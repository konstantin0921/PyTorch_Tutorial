{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs685 NLM implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxrvx86L4V0-"
      },
      "source": [
        "sentences = [\n",
        "             'bob likes sheep',\n",
        "             'alice is fast',\n",
        "             'cs685 is fun',\n",
        "             'i love lamp'\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NqNceOh4kOw"
      },
      "source": [
        "# given the first two words of each sentence, we'll try to predict the third word using a fixed window NLM\n",
        "\n",
        "# before we start any modeling, we have to tokenize our input and convert the words to indices\n",
        "\n",
        "vocab = {} # map from word type to index\n",
        "inputs = [] # store an indexified version of each sentence\n",
        "\n",
        "for sent in sentences:\n",
        "  sent_idxes = []\n",
        "\n",
        "  words = sent.split()\n",
        "  for w in words:\n",
        "    if w not in vocab:\n",
        "      vocab[w] = len(vocab) # add a new word type\n",
        "    sent_idxes.append(vocab[w])\n",
        "  \n",
        "  inputs.append(sent_idxes)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgWVPE316Hcn",
        "outputId": "709efaf4-e7a5-4f7c-d862-b5ebcf43e3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bob': 0, 'likes': 1, 'sheep': 2, 'alice': 3, 'is': 4, 'fast': 5, 'cs685': 6, 'fun': 7, 'i': 8, 'love': 9, 'lamp': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDbIlXYR6Jal",
        "outputId": "74dd8104-bf9f-4de9-eb36-3310f8286503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(inputs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 2], [3, 4, 5], [6, 4, 7], [8, 9, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEPXdUT96L0X"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAuF7cgx6wDO",
        "outputId": "86ec6b28-ae40-4343-8d7b-4dc9c38ad312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# two things:\n",
        "# 1. convert to LongTensor\n",
        "# 2. define inputs/outputs, the first two words and the third word\n",
        "prefixes = torch.LongTensor([sent[:2] for sent in inputs])\n",
        "labels = torch.LongTensor([sent[2] for sent in inputs])\n",
        "\n",
        "print(prefixes)\n",
        "print(labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1],\n",
            "        [3, 4],\n",
            "        [6, 4],\n",
            "        [8, 9]])\n",
            "tensor([ 2,  5,  7, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjOkabOH7eGD"
      },
      "source": [
        "# define the network\n",
        "import torch.nn as nn\n",
        "\n",
        "class NLM(nn.Module):\n",
        "    # two things you need to do\n",
        "    # 1. init function (initializes all the **params** of the network)\n",
        "    # 2. forward function (defines the forward computations)\n",
        "    def __init__(self, d_embedding, d_hidden, window_size, len_vocab):\n",
        "        super(NLM, self).__init__() # initialize the base Module class\n",
        "        self.d_embs = d_embedding \n",
        "        self.embeds = nn.Embedding(len_vocab, d_embedding)\n",
        "        # concatenate embeddings > hidden\n",
        "        self.W_hid = nn.Linear(d_embedding * window_size, d_hidden)\n",
        "        # hidden > output probability distribution over vocab\n",
        "        self.W_out = nn.Linear(d_hidden, len_vocab)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input): # each input will be a batch of prefixes\n",
        "        batch_size, window_size = input.size()\n",
        "        embs = self.embeds(input) # 4 x 2 x 5\n",
        "\n",
        "        # next, concatenate the prefix embeddings together\n",
        "        concat_embs = embs.view(batch_size, window_size * self.d_embs) # 4 x 10\n",
        "        \n",
        "        # we project this to the hidden space\n",
        "        hiddens = self.W_hid(concat_embs) # 4 x d_hidden\n",
        "        # finally, project hiddens to vocabulary space\n",
        "        outs = self.W_out(hiddens)\n",
        "        \n",
        "\n",
        "        # probs = nn.functional.softmax(outs, dim=1)\n",
        "\n",
        "        return outs # return unnormalized probability, alsk known as \"logits\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdEXnvtT_xw7"
      },
      "source": [
        "network = NLM(d_embedding=5, d_hidden=12, window_size=2, len_vocab=len(vocab))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEXwWUNs_7LW",
        "outputId": "ae2b45a9-3f6c-4f43-9c4f-2a45ac9ec570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network(prefixes)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0430,  0.3760, -0.0404,  0.3504,  0.4570, -0.2930, -0.4358,  0.1522,\n",
              "          0.0560, -0.0793, -0.3191],\n",
              "        [-0.4502, -0.2621,  0.2912,  0.1220,  0.3365, -0.4783, -0.0571, -0.1595,\n",
              "          0.2648, -0.5140, -0.3851],\n",
              "        [-0.3595, -0.0772,  0.2197,  0.2927,  0.2890, -0.2596, -0.1193, -0.2810,\n",
              "         -0.0440, -0.7078, -0.5025],\n",
              "        [-0.0506, -0.3506,  0.4256,  0.5166,  0.5341, -0.3084,  0.2623, -0.0991,\n",
              "          0.0066,  0.0313, -0.0552]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8eVaiXACdY"
      },
      "source": [
        "num_epochs = 30\n",
        "learning_rate = 0.1\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=network.parameters(), lr=learning_rate)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FUx9vAlYM-V",
        "outputId": "b21e4b2d-b5a5-4099-bf16-6b8813d79505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training loop\n",
        "for i in range(num_epochs):\n",
        "    logits = network(prefixes)\n",
        "    loss = loss_fn(logits, labels)\n",
        "    print(f'epochs[{i+1}/{num_epochs}]loss: {loss.item():.4f}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs[1/30]loss: 0.2512\n",
            "epochs[2/30]loss: 0.2353\n",
            "epochs[3/30]loss: 0.2206\n",
            "epochs[4/30]loss: 0.2071\n",
            "epochs[5/30]loss: 0.1946\n",
            "epochs[6/30]loss: 0.1831\n",
            "epochs[7/30]loss: 0.1724\n",
            "epochs[8/30]loss: 0.1625\n",
            "epochs[9/30]loss: 0.1533\n",
            "epochs[10/30]loss: 0.1447\n",
            "epochs[11/30]loss: 0.1368\n",
            "epochs[12/30]loss: 0.1294\n",
            "epochs[13/30]loss: 0.1226\n",
            "epochs[14/30]loss: 0.1162\n",
            "epochs[15/30]loss: 0.1103\n",
            "epochs[16/30]loss: 0.1048\n",
            "epochs[17/30]loss: 0.0997\n",
            "epochs[18/30]loss: 0.0949\n",
            "epochs[19/30]loss: 0.0904\n",
            "epochs[20/30]loss: 0.0863\n",
            "epochs[21/30]loss: 0.0824\n",
            "epochs[22/30]loss: 0.0787\n",
            "epochs[23/30]loss: 0.0753\n",
            "epochs[24/30]loss: 0.0722\n",
            "epochs[25/30]loss: 0.0692\n",
            "epochs[26/30]loss: 0.0664\n",
            "epochs[27/30]loss: 0.0637\n",
            "epochs[28/30]loss: 0.0613\n",
            "epochs[29/30]loss: 0.0589\n",
            "epochs[30/30]loss: 0.0568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjRtcAOhYzTz",
        "outputId": "8df495cc-3011-44d4-cb1b-f808812f5ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rev_vocab = dict((idx, word) for (word, idx) in vocab.items())\n",
        "rev_vocab"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'bob',\n",
              " 1: 'likes',\n",
              " 2: 'sheep',\n",
              " 3: 'alice',\n",
              " 4: 'is',\n",
              " 5: 'fast',\n",
              " 6: 'cs685',\n",
              " 7: 'fun',\n",
              " 8: 'i',\n",
              " 9: 'love',\n",
              " 10: 'lamp'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwLQDLYRd9FQ",
        "outputId": "ccf57b5f-4899-424d-8598-61ba2ba38897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "boblikes = prefixes[0].unsqueeze(0)\n",
        "\n",
        "print(boblikes.size())\n",
        "\n",
        "logits = network(boblikes)\n",
        "probs = nn.functional.softmax(logits, dim=1).squeeze()\n",
        "\n",
        "argmax_idx = torch.argmax(probs).item()\n",
        "print(probs)\n",
        "print(argmax_idx)\n",
        "print(f'given \"bob likes\", the model prediction as next word  is: [{rev_vocab[argmax_idx]}], probability is {probs[argmax_idx]}')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2])\n",
            "tensor([1.6756e-03, 2.5217e-03, 9.7605e-01, 1.0478e-03, 2.4076e-03, 6.0406e-03,\n",
            "        2.2282e-03, 4.8825e-04, 2.3747e-03, 3.0853e-03, 2.0833e-03],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "given \"bob likes\", the model prediction as next word  is: [sheep], probability is 0.9760469198226929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nbVRBLCeWAB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}